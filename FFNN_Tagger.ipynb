{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI_rMuMecmdr",
        "outputId": "18324aab-23e5-4e0f-9e42-9b872b86c632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting conllu\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-4.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Eh27a4ZvcqBh"
      },
      "outputs": [],
      "source": [
        "from conllu import parse,TokenList,Token\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset\n",
        "from torchtext.vocab import build_vocab_from_iterator,Vocab\n",
        "from torch.utils.data import DataLoader\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score,recall_score,precision_score,accuracy_score,confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WYOvZMiRcsUD"
      },
      "outputs": [],
      "source": [
        "START_TOKEN = \"<s>\"\n",
        "END_TOKEN = \"</s>\"\n",
        "UNKNOWN_TOKEN = \"<unk>\"\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "epochs=10\n",
        "EMBEDDING_SIZE=20\n",
        "HIDDEN_SIZE=120\n",
        "lrate=1e-2\n",
        "BATCH_SIZE=10\n",
        "p=4\n",
        "s=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ucSPDjbnc4Ij"
      },
      "outputs": [],
      "source": [
        "def filter_sentences_by_tag(sentences, pos_tags, tag_to_exclude='SYM'): # removing SYM tag sentences\n",
        "    filtered_sentences = []\n",
        "    filtered_pos_tags = []\n",
        "    for sentence, tags in zip(sentences, pos_tags):\n",
        "        if tag_to_exclude not in tags:\n",
        "            filtered_sentences.append(sentence)\n",
        "            filtered_pos_tags.append(tags)\n",
        "    return filtered_sentences, filtered_pos_tags\n",
        "def extract_tokens_and_tags(sentences):\n",
        "    token_sequences = []\n",
        "    tag_sequences = []\n",
        "    for sentence in sentences:\n",
        "        tokens = []\n",
        "        tags = []\n",
        "        for token in sentence:\n",
        "            tokens.append(token[\"form\"])\n",
        "            tags.append(token[\"upos\"])\n",
        "        token_sequences.append(tokens)\n",
        "        tag_sequences.append(tags)\n",
        "    return token_sequences, tag_sequences\n",
        "def replace_low_frequency_words(sentences, threshold=3):\n",
        "    word_counts = Counter(word for sentence in sentences for word in sentence)\n",
        "    replaced_sentences = [\n",
        "        [UNKNOWN_TOKEN if word_counts[word] < threshold else word for word in sentence]\n",
        "        for sentence in sentences\n",
        "    ]\n",
        "    return replaced_sentences\n",
        "def append_tokens(p, s, sentences):\n",
        "    for sentence in sentences:\n",
        "        for _ in range(p):\n",
        "            sentence.insert(0,START_TOKEN)\n",
        "        for _ in range(s):\n",
        "            sentence.append(END_TOKEN)\n",
        "    return sentences\n",
        "def append_labels(p, s, sentences):\n",
        "    for sentence in sentences:\n",
        "        for _ in range(p):\n",
        "            sentence.insert(0,0)\n",
        "        for _ in range(s):\n",
        "            sentence.append(0)\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_DL0dcwUcx-h"
      },
      "outputs": [],
      "source": [
        "class EntityDataset(Dataset):\n",
        "  def __init__(self, sent, tok,p,s, vocabulary:Vocab|None=None):\n",
        "    \"\"\"Initialize the dataset. Setup Code goes here\"\"\"\n",
        "    self.sentences = sent\n",
        "    self.labels = tok\n",
        "    words = []\n",
        "    labels = []\n",
        "    self.p=p\n",
        "    self.s=s\n",
        "    for sentence, label in zip(self.sentences, self.labels):\n",
        "      for word, label in zip(sentence, label):\n",
        "        if word!=START_TOKEN and word!=END_TOKEN:\n",
        "          words.append(word)\n",
        "          labels.append(label)\n",
        "    self.words=words\n",
        "    self.labels=labels\n",
        "    if vocabulary is None:\n",
        "      self.vocabulary = build_vocab_from_iterator(self.sentences, specials=[UNKNOWN_TOKEN])\n",
        "      self.vocabulary.set_default_index(self.vocabulary[UNKNOWN_TOKEN])\n",
        "    else:\n",
        "      self.vocabulary = vocabulary\n",
        "    inp_dt=[]\n",
        "    inp_labels=[]\n",
        "    for sen,lab in zip(sent, tok):\n",
        "      for i in range(self.p,len(sen)-self.s):\n",
        "        toks_to_add=sen[i-self.p:i+self.s+1]\n",
        "        inp_dt.append(toks_to_add)\n",
        "        inp_labels.append(lab[i])\n",
        "    self.inp_dt=inp_dt\n",
        "    self.inp_labels=inp_labels\n",
        "  def __len__(self) -> int:\n",
        "    \"\"\"Returns number of datapoints.\"\"\"\n",
        "    return len(self.words)\n",
        "\n",
        "  def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Get the datapoint at `index`.\"\"\"\n",
        "    return torch.tensor(self.vocabulary.lookup_indices(self.inp_dt[index])), torch.tensor(self.inp_labels[index])\n",
        "\n",
        "  def collate(self, batch: list[tuple[torch.Tensor, torch.Tensor]]) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Given a list of datapoints, batch them together\"\"\"\n",
        "    sentences = [i[0] for i in batch]\n",
        "    labels = [i[1] for i in batch]\n",
        "    padded_sentences = pad_sequence(sentences, batch_first=True, padding_value=self.vocabulary[PAD_TOKEN])\n",
        "    labels=torch.tensor(labels)\n",
        "    labels=labels.view(-1,1)\n",
        "    return padded_sentences,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9pvn7KxHcywA"
      },
      "outputs": [],
      "source": [
        "def get_datasets_ffNN(p,s):\n",
        "  with open('/content/en_atis-ud-train.conllu') as f:\n",
        "    train_sentences = parse(f.read())\n",
        "  tok_seq,tag_seq=extract_tokens_and_tags(train_sentences)\n",
        "  tok_seq=replace_low_frequency_words(tok_seq)\n",
        "  tok_seq=append_tokens(p,s,tok_seq)\n",
        "  unique_tags = set(tag for tags in tag_seq for tag in tags)\n",
        "  tag_to_id = {tag: idx+1 for idx, tag in enumerate(sorted(unique_tags))}\n",
        "  print(tag_to_id)\n",
        "  new_tag_seq=[[tag_to_id[tag] for tag in tags] for tags in tag_seq]\n",
        "  new_tag_seq=append_labels(p,s,new_tag_seq)\n",
        "  train_dataset=EntityDataset(tok_seq,new_tag_seq,p,s)\n",
        "  with open('/content/en_atis-ud-test.conllu') as f:\n",
        "    test_sentences = parse(f.read())\n",
        "  with open('/content/en_atis-ud-dev.conllu') as f:\n",
        "    val_sentences = parse(f.read())\n",
        "  test_toks,test_tags=extract_tokens_and_tags(test_sentences)\n",
        "  val_toks,val_tags=extract_tokens_and_tags(val_sentences)\n",
        "  val_toks,val_tags=filter_sentences_by_tag(val_toks,val_tags)\n",
        "  test_tags=[[tag_to_id[tag] for tag in tags] for tags in test_tags]\n",
        "  val_tags=[[tag_to_id[tag] for tag in tags] for tags in val_tags]\n",
        "  val_toks=append_tokens(p,s,val_toks)\n",
        "  test_toks=append_tokens(p,s,test_toks)\n",
        "  val_tags=append_labels(p,s,val_tags)\n",
        "  test_tags=append_labels(p,s,test_tags)\n",
        "  val_dataset=EntityDataset(val_toks,val_tags,p,s,vocabulary=train_dataset.vocabulary)\n",
        "  test_dataset=EntityDataset(test_toks,test_tags,p,s,vocabulary=train_dataset.vocabulary)\n",
        "  return train_dataset,val_dataset,test_dataset,tag_to_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z30z4X3idM-o",
        "outputId": "4a3ae853-75f3-4100-9db2-cb37f75b25a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ADJ': 1, 'ADP': 2, 'ADV': 3, 'AUX': 4, 'CCONJ': 5, 'DET': 6, 'INTJ': 7, 'NOUN': 8, 'NUM': 9, 'PART': 10, 'PRON': 11, 'PROPN': 12, 'VERB': 13}\n"
          ]
        }
      ],
      "source": [
        "train_dataset,val_dataset,test_dataset,tag_to_id=get_datasets_ffNN(p,s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "ofgyjKjDdPeS"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_dataloader=DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OP4S684fdQ-4"
      },
      "outputs": [],
      "source": [
        "class FeedForwardNN(torch.nn.Module):\n",
        "  def __init__(self, p, s, out_size, vocabulary_size: int, embedding_size: int, hidden_size: int):\n",
        "    super().__init__()\n",
        "    self.embedding_module = torch.nn.Embedding(vocabulary_size, embedding_size)\n",
        "    self.entity_predictor = torch.nn.Sequential(\n",
        "                                    torch.nn.Linear(embedding_size*(p+s+1), hidden_size),\n",
        "                                    torch.nn.ReLU(),\n",
        "                                    torch.nn.Linear(hidden_size, out_size))\n",
        "  def forward(self, word_seq: torch.Tensor):\n",
        "    embedding = self.embedding_module(word_seq)\n",
        "    embedding=embedding.reshape(embedding.shape[0],-1)\n",
        "    return self.entity_predictor(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WVreQsoddS6B",
        "outputId": "374438eb-3aa9-4916-e2c6-89d17bf94d14"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"mps\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(\"mps\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "bOGZqSELdU0t"
      },
      "outputs": [],
      "source": [
        "entity_predictor=FeedForwardNN(p,s,len(tag_to_id),len(train_dataset.vocabulary),EMBEDDING_SIZE,HIDDEN_SIZE)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(entity_predictor.parameters(), lr=lrate)\n",
        "entity_predictor = entity_predictor.to(device)\n",
        "\n",
        "for epoch_num in range(epochs):\n",
        "  entity_predictor.train()\n",
        "  for batch_num, (words, tags) in enumerate(train_dataloader):\n",
        "    (words, tags) = (words.to(device), tags.to(device))\n",
        "    one_hot_tags=(torch.nn.functional.one_hot(tags - 1, num_classes=len(tag_to_id))).float()\n",
        "    one_hot_tags=torch.squeeze(one_hot_tags,dim=1)\n",
        "    pred = entity_predictor(words)\n",
        "    loss = loss_fn(pred, one_hot_tags)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "  # entity_predictor.eval()\n",
        "  # with torch.no_grad():\n",
        "  #   test_loss = 0\n",
        "  #   for batch_num, (words, tags) in enumerate(val_dataloader):\n",
        "  #     (words, tags) = (words.to(device), tags.to(device))\n",
        "  #     one_hot_tags=(torch.nn.functional.one_hot(tags - 1, num_classes=len(tag_to_id))).float()\n",
        "  #     one_hot_tags=torch.squeeze(one_hot_tags,dim=1)\n",
        "  #     pred = entity_predictor(words)\n",
        "  #     test_loss += loss_fn(pred, one_hot_tags)\n",
        "  # print(f\"Validation error: {test_loss/len(val_dataloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMWd7H6kg9Q-",
        "outputId": "e5fc4013-425d-46fa-88a2-8cecf9f23219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score on dev set: 0.9597285067873303\n",
            "F1-Score(micro) on dev set: 0.9597285067873303\n",
            "F1-Score(macro) on dev set: 0.9383967199957396\n",
            "Recall(micro) Score on dev set: 0.9597285067873303\n",
            "Recall(macro) Score on dev set: 0.9201097962278777\n",
            "Precision(micro) Score on dev set: 0.9597285067873303\n",
            "Precision(macro) Score on dev set: 0.965264128172647\n",
            "Confusion matrix for dev set:\n",
            " [[ 188    0    0    0    0    0    0    8    0    0    0    2   28]\n",
            " [   0 1378    0    0    0    0    0    0    0    6   21    0    9]\n",
            " [   2    0   44    0    0    0    0    2    0    0    0    0   11]\n",
            " [   0    0    0  242    0    0    0    0    0    0    1    0   21]\n",
            " [   0    0    0    0  106    0    0    0    0    0    0    0    1]\n",
            " [   0    7    0    0    1  534    0    0    0    0   16    0    9]\n",
            " [   0    0    0    0    0    0   34    0    0    0    0    0    1]\n",
            " [   0    1    0    0    0    0    0 1093    0    0    0    8   35]\n",
            " [   0    0    0    0    0    0    0    1  103    0    0    0   27]\n",
            " [   0    3    0    0    0    0    0    0    0   64    0    0    6]\n",
            " [   0    0    0    0    0    1    0    0    0    0  409    0    3]\n",
            " [   0    0    0    0    1    0    0    2    0    0    0 1518   30]\n",
            " [   0    0    0    1    0    0    0    2    0    0    0    0  650]]\n"
          ]
        }
      ],
      "source": [
        "entity_predictor.eval()\n",
        "predictions=[]\n",
        "true_vals=[]\n",
        "with torch.no_grad():\n",
        "  for batch_num, (words, tags) in enumerate(val_dataloader):\n",
        "    (words, tags) = (words.to(device), tags.to(device))\n",
        "    one_hot_tags=(torch.nn.functional.one_hot(tags - 1, num_classes=len(tag_to_id))).float()\n",
        "    one_hot_tags=torch.squeeze(one_hot_tags,dim=1)\n",
        "    pred = entity_predictor(words)\n",
        "    pred_max_index = torch.argmax(pred, dim=1) + 1\n",
        "    if tags.dim()>1:\n",
        "      tags=tags.squeeze(dim=1)\n",
        "    true_vals.extend(tags.flatten().cpu())\n",
        "    predictions.extend(pred_max_index.flatten().cpu())\n",
        "predictions=torch.stack(predictions).numpy()\n",
        "true_vals=torch.stack(true_vals).numpy()\n",
        "f1_micro=f1_score(true_vals,predictions,average='micro')\n",
        "f1_macro=f1_score(true_vals,predictions,average='macro')\n",
        "rec_micro=recall_score(true_vals,predictions,average='micro')\n",
        "rec_macro=recall_score(true_vals,predictions,average='macro')\n",
        "pre_micro=precision_score(true_vals,predictions,average='micro')\n",
        "pre_macro=precision_score(true_vals,predictions,average='macro')\n",
        "print(f'Accuracy Score on dev set: {accuracy_score(true_vals,predictions)}')\n",
        "print(f'F1-Score(micro) on dev set: {f1_micro}')\n",
        "print(f'F1-Score(macro) on dev set: {f1_macro}')\n",
        "print(f'Recall(micro) Score on dev set: {rec_micro}')\n",
        "print(f'Recall(macro) Score on dev set: {rec_macro}')\n",
        "print(f'Precision(micro) Score on dev set: {pre_micro}')\n",
        "print(f'Precision(macro) Score on dev set: {pre_macro}')\n",
        "print(f'Confusion matrix for dev set:\\n {confusion_matrix(true_vals,predictions)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAQRZSbodWqb",
        "outputId": "ded54382-adaa-4138-d304-ee749999c807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score on test set: 0.958966565349544\n",
            "F1-Score(micro) on test set: 0.958966565349544\n",
            "F1-Score(macro) on test set: 0.9294211099798706\n",
            "Recall(micro) Score on test set: 0.958966565349544\n",
            "Recall(macro) Score on test set: 0.9103940064232436\n",
            "Precision(micro) Score on test set: 0.958966565349544\n",
            "Precision(macro) Score on test set: 0.9617202131153981\n",
            "Confusion matrix for test set:\n",
            " [[ 199    0    0    0    0    0    0    3    0    0    0    2   16]\n",
            " [   0 1389    0    0    0    0    0    0    0    1   30    0   14]\n",
            " [   7    0   45    0    0    0    0    0    0    1    0    1   22]\n",
            " [   0    0    0  230    0    0    0    1    0    0    2    0   23]\n",
            " [   0    0    1    0  106    0    0    0    0    0    0    0    2]\n",
            " [   1    1    0    0    0  494    0    0    0    0    3    2   11]\n",
            " [   0    0    0    0    0    0   34    0    0    0    0    0    2]\n",
            " [   1    1    0    0    0    0    0 1124    1    0    0    1   38]\n",
            " [   0    0    0    0    0    0    0    0   94    0    0    1   32]\n",
            " [   0    2    0    0    0    0    0    0    0   52    0    0    2]\n",
            " [   0    0    0    0    0    2    1    0    1    0  385    0    3]\n",
            " [   1    0    0    0    0    0    0    2    0    0    0 1530   34]\n",
            " [   0    0    0    0    0    0    0    1    0    0    0    0  628]]\n"
          ]
        }
      ],
      "source": [
        "entity_predictor.eval()\n",
        "predictions=[]\n",
        "true_vals=[]\n",
        "with torch.no_grad():\n",
        "  for batch_num, (words, tags) in enumerate(test_dataloader):\n",
        "    (words, tags) = (words.to(device), tags.to(device))\n",
        "    one_hot_tags=(torch.nn.functional.one_hot(tags - 1, num_classes=len(tag_to_id))).float()\n",
        "    one_hot_tags=torch.squeeze(one_hot_tags,dim=1)\n",
        "    pred = entity_predictor(words)\n",
        "    pred_max_index = torch.argmax(pred, dim=1) + 1\n",
        "    if tags.dim()>1:\n",
        "      tags=tags.squeeze(dim=1)\n",
        "    true_vals.extend(tags.flatten().cpu())\n",
        "    predictions.extend(pred_max_index.flatten().cpu())\n",
        "predictions=torch.stack(predictions).numpy()\n",
        "true_vals=torch.stack(true_vals).numpy()\n",
        "f1_micro=f1_score(true_vals,predictions,average='micro')\n",
        "f1_macro=f1_score(true_vals,predictions,average='macro')\n",
        "rec_micro=recall_score(true_vals,predictions,average='micro')\n",
        "rec_macro=recall_score(true_vals,predictions,average='macro')\n",
        "pre_micro=precision_score(true_vals,predictions,average='micro')\n",
        "pre_macro=precision_score(true_vals,predictions,average='macro')\n",
        "print(f'Accuracy Score on test set: {accuracy_score(true_vals,predictions)}')\n",
        "print(f'F1-Score(micro) on test set: {f1_micro}')\n",
        "print(f'F1-Score(macro) on test set: {f1_macro}')\n",
        "print(f'Recall(micro) Score on test set: {rec_micro}')\n",
        "print(f'Recall(macro) Score on test set: {rec_macro}')\n",
        "print(f'Precision(micro) Score on test set: {pre_micro}')\n",
        "print(f'Precision(macro) Score on test set: {pre_macro}')\n",
        "print(f'Confusion matrix for test set:\\n {confusion_matrix(true_vals,predictions)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "AqlfAd1Vz9hf"
      },
      "outputs": [],
      "source": [
        "# pred_vals_graph=[]\n",
        "# for val in range(0,5):\n",
        "#   p=val\n",
        "#   s=val\n",
        "#   train_dataset,val_dataset,test_dataset,tag_to_id=get_datasets_ffNN(p,s)\n",
        "#   train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "#   val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "#   test_dataloader=DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "#   entity_predictor=FeedForwardNN(p,s,len(tag_to_id),len(train_dataset.vocabulary),EMBEDDING_SIZE,HIDDEN_SIZE)\n",
        "#   loss_fn = torch.nn.CrossEntropyLoss()\n",
        "#   optimizer = torch.optim.Adam(entity_predictor.parameters(), lr=lrate)\n",
        "#   entity_predictor = entity_predictor.to(device)\n",
        "#   # train loop\n",
        "#   for epoch_num in range(epochs):\n",
        "#     entity_predictor.train()\n",
        "#     for batch_num, (words, tags) in enumerate(train_dataloader):\n",
        "#       (words, tags) = (words.to(device), tags.to(device))\n",
        "#       one_hot_tags=(torch.nn.functional.one_hot(tags - 1, num_classes=len(tag_to_id))).float()\n",
        "#       one_hot_tags=torch.squeeze(one_hot_tags,dim=1)\n",
        "#       pred = entity_predictor(words)\n",
        "#       loss = loss_fn(pred, one_hot_tags)\n",
        "#       loss.backward()\n",
        "#       optimizer.step()\n",
        "#       optimizer.zero_grad()\n",
        "#   # accuracy on val set\n",
        "#   entity_predictor.eval()\n",
        "#   predictions=[]\n",
        "#   true_vals=[]\n",
        "#   with torch.no_grad():\n",
        "#     for batch_num, (words, tags) in enumerate(val_dataloader):\n",
        "#       (words, tags) = (words.to(device), tags.to(device))\n",
        "#       one_hot_tags=(torch.nn.functional.one_hot(tags - 1, num_classes=len(tag_to_id))).float()\n",
        "#       one_hot_tags=torch.squeeze(one_hot_tags,dim=1)\n",
        "#       pred = entity_predictor(words)\n",
        "#       pred_max_index = torch.argmax(pred, dim=1) + 1\n",
        "#       if tags.dim()>1:\n",
        "#         tags=tags.squeeze(dim=1)\n",
        "#       true_vals.extend(tags.flatten().cpu())\n",
        "#       predictions.extend(pred_max_index.flatten().cpu())\n",
        "#   predictions=torch.stack(predictions).numpy()\n",
        "#   true_vals=torch.stack(true_vals).numpy()\n",
        "#   pred_vals_graph.append(accuracy_score(true_vals,predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "b4ShBCsZ4G7Y"
      },
      "outputs": [],
      "source": [
        "# plt.bar(range(0,5), pred_vals_graph)\n",
        "# plt.ylim(0.9, 1)\n",
        "# plt.xlabel('context_window')\n",
        "# plt.ylabel('Accuracy on dev set')\n",
        "# plt.title('context_window vs dev set accuracy for FFNN')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "lLtOjF4slt4o"
      },
      "outputs": [],
      "source": [
        "# torch.save(entity_predictor,'FFNN_POS_Tagger.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5Pxp1F_YIaSi"
      },
      "outputs": [],
      "source": [
        "entity_predictor=torch.load('FFNN_POS_Tagger.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlEDJRyaIYqz",
        "outputId": "e59a9cea-1de5-4ce2-8e55-7670a51dcd3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from nltk.tokenize import RegexpTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXiJ6knrIhfX",
        "outputId": "15e92e4b-fcbd-47c3-fecc-8b1a8923499f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'ADJ', 2: 'ADP', 3: 'ADV', 4: 'AUX', 5: 'CCONJ', 6: 'DET', 7: 'INTJ', 8: 'NOUN', 9: 'NUM', 10: 'PART', 11: 'PRON', 12: 'PROPN', 13: 'VERB'}\n"
          ]
        }
      ],
      "source": [
        "def tokenise(text):\n",
        "    tokenizer=RegexpTokenizer(r'\\w+')\n",
        "    tokens=tokenizer.tokenize(text)\n",
        "    return tokens\n",
        "def reverse_dict(original_dict):\n",
        "    reverse_dict = {v: k for k, v in original_dict.items()}\n",
        "    return reverse_dict\n",
        "rev_tag_to_id=reverse_dict(tag_to_id)\n",
        "print(rev_tag_to_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szg7xq2EIiBv",
        "outputId": "b1e03a1b-7e03-4a6a-dd5a-5d9ab0bedb38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is an aeroplane in a city of pitsburg\n",
            "['is', 'an', 'aeroplane', 'in', 'a', 'city', 'of', 'pitsburg']\n"
          ]
        }
      ],
      "source": [
        "user_inp=input()\n",
        "tok_sent=tokenise(user_inp)\n",
        "orig_sent=[]\n",
        "for x in tok_sent:\n",
        "  orig_sent.append(x)\n",
        "print(tok_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "k1V_304nIkJb"
      },
      "outputs": [],
      "source": [
        "ntok_sent=(append_tokens(p,s,[tok_sent]))[0]\n",
        "inp_data=[]\n",
        "for i in range(p,len(ntok_sent)-s):\n",
        "  window=ntok_sent[i-p:i+s+1]\n",
        "  encoded_inp=train_dataset.vocabulary.lookup_indices(window)\n",
        "  inp_data.append(encoded_inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdbMsSPbInSL",
        "outputId": "7851213c-20fb-4c9e-819b-f25297521e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([13,  6, 13,  2,  6, 12,  2, 13])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  temp=[]\n",
        "  for x in inp_data:\n",
        "    temp.append(torch.tensor(x))\n",
        "  inp_data=torch.stack(temp)\n",
        "  res=entity_predictor(inp_data)\n",
        "  pred_maxcol=np.argmax(res, axis=1)+1\n",
        "  print(pred_maxcol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwIY0WpyIrvn",
        "outputId": "ba740730-365f-477a-d8b5-5d5e95920cfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is VERB\n",
            "an DET\n",
            "aeroplane VERB\n",
            "in ADP\n",
            "a DET\n",
            "city PROPN\n",
            "of ADP\n",
            "pitsburg VERB\n"
          ]
        }
      ],
      "source": [
        "for a,t in zip(orig_sent,pred_maxcol):\n",
        "    print(a+\" \"+rev_tag_to_id[int(t)])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
